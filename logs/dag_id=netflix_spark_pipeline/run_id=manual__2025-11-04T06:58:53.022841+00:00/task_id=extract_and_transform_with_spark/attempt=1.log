{"timestamp":"2025-11-04T06:58:53.342981Z","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager","filename":"manager.py","lineno":179}
{"timestamp":"2025-11-04T06:58:53.343248Z","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/netflix_pipeline_spark.py","logger":"airflow.models.dagbag.DagBag","filename":"dagbag.py","lineno":593}
{"timestamp":"2025-11-04T06:58:53.484044Z","level":"warning","event":"The `airflow.decorators.task` attribute is deprecated. Please use `'airflow.sdk.task'`.","category":"DeprecatedImportWarning","filename":"/opt/airflow/dags/netflix_pipeline_spark.py","lineno":3,"logger":"py.warnings"}
{"timestamp":"2025-11-04T06:58:53.538210Z","level":"error","event":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/bin/load-spark-env.sh: line 68: ps: command not found","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:58:54.189987Z","level":"error","event":"Setting default log level to \"WARN\".","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:58:54.190239Z","level":"error","event":"To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:58:54.299615Z","level":"error","event":"25/11/04 06:58:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:58:54.693257Z","level":"info","event":"âœ… Spark initialized - Version: 3.5.0","logger":"task.stdout"}
{"timestamp":"2025-11-04T06:58:56.702216Z","level":"info","event":"ðŸ“Š Loaded 8809 records","logger":"task.stdout"}
{"timestamp":"2025-11-04T06:58:56.897585Z","level":"info","event":"âœ… Cleaned: 8807 records using PySpark","logger":"task.stdout"}
{"timestamp":"2025-11-04T06:58:57.190651Z","level":"error","event":"25/11/04 06:58:57 ERROR RetryingBlockTransferor: Exception while beginning fetch of 1 outstanding blocks","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:58:57.190859Z","level":"error","event":"java.io.IOException: Failed to connect to e7e3718d922e/172.19.0.8:45479","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:58:57.190943Z","level":"error","event":"\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:294)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:58:57.191011Z","level":"error","event":"\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:58:57.191081Z","level":"error","event":"\tat org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:131)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:58:57.191125Z","level":"error","event":"\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.transferAllOutstanding(RetryingBlockTransferor.java:173)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:58:57.191180Z","level":"error","event":"\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.start(RetryingBlockTransferor.java:152)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:58:57.191224Z","level":"error","event":"\tat org.apache.spark.network.netty.NettyBlockTransferService.fetchBlocks(NettyBlockTransferService.scala:151)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:58:57.191265Z","level":"error","event":"\tat org.apache.spark.network.BlockTransferService.fetchBlockSync(BlockTransferService.scala:102)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:58:57.191308Z","level":"error","event":"\tat org.apache.spark.storage.BlockManager.fetchRemoteManagedBuffer(BlockManager.scala:1172)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:58:57.191344Z","level":"error","event":"\tat org.apache.spark.storage.BlockManager.$anonfun$getRemoteBlock$8(BlockManager.scala:1116)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:58:57.191379Z","level":"error","event":"\tat scala.Option.orElse(Option.scala:447)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:58:57.191530Z","level":"error","event":"\tat org.apache.spark.storage.BlockManager.getRemoteBlock(BlockManager.scala:1116)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:58:57.191609Z","level":"error","event":"\tat org.apache.spark.storage.BlockManager.getRemoteBytes(BlockManager.scala:1256)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:58:57.191673Z","level":"error","event":"\tat org.apache.spark.scheduler.TaskResultGetter$$anon$3.$anonfun$run$1(TaskResultGetter.scala:88)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:58:57.191741Z","level":"error","event":"\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:58:57.191828Z","level":"error","event":"\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:58:57.191909Z","level":"error","event":"\tat org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:63)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:58:57.191953Z","level":"error","event":"\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:58:57.192002Z","level":"error","event":"\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:58:57.192047Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:58:57.192082Z","level":"error","event":"Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: e7e3718d922e/172.19.0.8:45479","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:58:57.192121Z","level":"error","event":"Caused by: java.net.ConnectException: Connection refused","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:58:57.192154Z","level":"error","event":"\tat java.base/sun.nio.ch.Net.pollConnect(Native Method)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:58:57.192204Z","level":"error","event":"\tat java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:58:57.192236Z","level":"error","event":"\tat java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:946)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:58:57.192268Z","level":"error","event":"\tat io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:337)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:58:57.192299Z","level":"error","event":"\tat io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:58:57.192331Z","level":"error","event":"\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:776)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:58:57.192363Z","level":"error","event":"\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:58:57.192394Z","level":"error","event":"\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:58:57.192428Z","level":"error","event":"\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:58:57.192460Z","level":"error","event":"\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:58:57.192490Z","level":"error","event":"\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:58:57.192525Z","level":"error","event":"\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:58:57.192557Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:02.201137Z","level":"error","event":"\r[Stage 6:>                                                          (0 + 1) / 1]\r25/11/04 06:59:02 ERROR RetryingBlockTransferor: Exception while beginning fetch of 1 outstanding blocks (after 1 retries)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:02.201551Z","level":"error","event":"java.io.IOException: Failed to connect to e7e3718d922e/172.19.0.8:45479","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:02.201682Z","level":"error","event":"\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:294)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:02.201799Z","level":"error","event":"\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:02.201892Z","level":"error","event":"\tat org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:131)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:02.201981Z","level":"error","event":"\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.transferAllOutstanding(RetryingBlockTransferor.java:173)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:02.202227Z","level":"error","event":"\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.lambda$initiateRetry$0(RetryingBlockTransferor.java:206)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:02.202332Z","level":"error","event":"\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:02.202382Z","level":"error","event":"\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:02.202424Z","level":"error","event":"\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:02.202466Z","level":"error","event":"\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:02.202502Z","level":"error","event":"\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:02.202541Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:02.202578Z","level":"error","event":"Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: e7e3718d922e/172.19.0.8:45479","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:02.202613Z","level":"error","event":"Caused by: java.net.ConnectException: Connection refused","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:02.202649Z","level":"error","event":"\tat java.base/sun.nio.ch.Net.pollConnect(Native Method)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:02.202683Z","level":"error","event":"\tat java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:02.202717Z","level":"error","event":"\tat java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:946)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:02.202751Z","level":"error","event":"\tat io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:337)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:02.202786Z","level":"error","event":"\tat io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:02.202819Z","level":"error","event":"\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:776)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:02.202900Z","level":"error","event":"\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:02.202937Z","level":"error","event":"\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:02.202974Z","level":"error","event":"\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:02.203009Z","level":"error","event":"\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:02.203042Z","level":"error","event":"\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:02.203082Z","level":"error","event":"\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:02.203165Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:07.212418Z","level":"error","event":"25/11/04 06:59:07 ERROR RetryingBlockTransferor: Exception while beginning fetch of 1 outstanding blocks (after 2 retries)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:07.213294Z","level":"error","event":"java.io.IOException: Failed to connect to e7e3718d922e/172.19.0.8:45479","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:07.213936Z","level":"error","event":"\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:294)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:07.214429Z","level":"error","event":"\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:07.214834Z","level":"error","event":"\tat org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:131)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:07.215285Z","level":"error","event":"\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.transferAllOutstanding(RetryingBlockTransferor.java:173)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:07.215708Z","level":"error","event":"\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.lambda$initiateRetry$0(RetryingBlockTransferor.java:206)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:07.216225Z","level":"error","event":"\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:07.216571Z","level":"error","event":"\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:07.216905Z","level":"error","event":"\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:07.217205Z","level":"error","event":"\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:07.217527Z","level":"error","event":"\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:07.217822Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:07.218162Z","level":"error","event":"Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: e7e3718d922e/172.19.0.8:45479","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:07.218434Z","level":"error","event":"Caused by: java.net.ConnectException: Connection refused","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:07.218672Z","level":"error","event":"\tat java.base/sun.nio.ch.Net.pollConnect(Native Method)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:07.219165Z","level":"error","event":"\tat java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:07.219464Z","level":"error","event":"\tat java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:946)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:07.219772Z","level":"error","event":"\tat io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:337)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:07.220047Z","level":"error","event":"\tat io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:07.220315Z","level":"error","event":"\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:776)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:07.220589Z","level":"error","event":"\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:07.220903Z","level":"error","event":"\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:07.221172Z","level":"error","event":"\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:07.221452Z","level":"error","event":"\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:07.221790Z","level":"error","event":"\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:07.222049Z","level":"error","event":"\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:07.222248Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:12.215636Z","level":"error","event":"25/11/04 06:59:12 ERROR RetryingBlockTransferor: Exception while beginning fetch of 1 outstanding blocks (after 3 retries)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:12.216059Z","level":"error","event":"java.io.IOException: Failed to connect to e7e3718d922e/172.19.0.8:45479","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:12.216229Z","level":"error","event":"\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:294)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:12.216422Z","level":"error","event":"\tat org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:12.216581Z","level":"error","event":"\tat org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:131)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:12.216746Z","level":"error","event":"\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.transferAllOutstanding(RetryingBlockTransferor.java:173)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:12.217010Z","level":"error","event":"\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.lambda$initiateRetry$0(RetryingBlockTransferor.java:206)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:12.217157Z","level":"error","event":"\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:12.217304Z","level":"error","event":"\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:12.217426Z","level":"error","event":"\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:12.217601Z","level":"error","event":"\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:12.217708Z","level":"error","event":"\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:12.217788Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:12.217871Z","level":"error","event":"Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: e7e3718d922e/172.19.0.8:45479","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:12.217960Z","level":"error","event":"Caused by: java.net.ConnectException: Connection refused","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:12.218063Z","level":"error","event":"\tat java.base/sun.nio.ch.Net.pollConnect(Native Method)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:12.218178Z","level":"error","event":"\tat java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:12.218326Z","level":"error","event":"\tat java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:946)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:12.218444Z","level":"error","event":"\tat io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:337)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:12.218571Z","level":"error","event":"\tat io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:12.218676Z","level":"error","event":"\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:776)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:12.218788Z","level":"error","event":"\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:12.218880Z","level":"error","event":"\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:12.219132Z","level":"error","event":"\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:12.219245Z","level":"error","event":"\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:12.219341Z","level":"error","event":"\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:12.219439Z","level":"error","event":"\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:12.219535Z","level":"error","event":"\tat java.base/java.lang.Thread.run(Thread.java:840)","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:12.220252Z","level":"error","event":"25/11/04 06:59:12 ERROR TaskSetManager: Task 0 in stage 6.0 failed 1 times; aborting job","logger":"task.stderr"}
{"timestamp":"2025-11-04T06:59:12.237472Z","level":"error","event":"Task failed with exception","logger":"task","filename":"task_runner.py","lineno":994,"error_detail":[{"exc_type":"Py4JJavaError","exc_value":"An error occurred while calling o56.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 6.0 failed 1 times, most recent failure: Lost task 0.0 in stage 6.0 (TID 6) (e7e3718d922e executor driver): TaskResultLost (result lost from block manager)\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2438)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2463)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1046)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:407)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1045)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:448)\n\tat org.apache.spark.sql.Dataset.$anonfun$collectToPython$1(Dataset.scala:4160)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4334)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4332)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:4332)\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:4157)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","exc_notes":[],"syntax_error":null,"is_cause":false,"frames":[{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":920,"name":"run"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/task_runner.py","lineno":1307,"name":"_execute_task"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/bases/operator.py","lineno":416,"name":"wrapper"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/bases/decorator.py","lineno":252,"name":"execute"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/bases/operator.py","lineno":416,"name":"wrapper"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/standard/operators/python.py","lineno":216,"name":"execute"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/standard/operators/python.py","lineno":239,"name":"execute_callable"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/airflow/sdk/execution_time/callback_runner.py","lineno":82,"name":"run"},{"filename":"/opt/airflow/dags/netflix_pipeline_spark.py","lineno":81,"name":"extract_and_transform_with_spark"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/pandas/conversion.py","lineno":202,"name":"toPandas"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/sql/dataframe.py","lineno":1257,"name":"collect"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/java_gateway.py","lineno":1322,"name":"__call__"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py","lineno":179,"name":"deco"},{"filename":"/home/airflow/.local/lib/python3.12/site-packages/py4j/protocol.py","lineno":326,"name":"get_return_value"}],"is_group":false,"exceptions":[]}]}
